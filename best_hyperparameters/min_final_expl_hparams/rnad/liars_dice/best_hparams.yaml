adam:
  b1: 0.0
  b2: 0.999
  eps: 1.0e-07
algorithm_name: rnad
batch_size: 32
c_vtrace: 0.25
clip_gradient: 1250
entropy_schedule_repeats:
- 1
entropy_schedule_size_value: 50000
eta_reward_transform: 0.1
finetune: None
learning_rate: 0.0001
nerd:
  beta: 2.0
  clip: 10000
policy_network_layers:
- 512
- 512
- 512
seed: None
state_representation: info_set
target_network_avg: 0.00025
trajectory_max: 100
