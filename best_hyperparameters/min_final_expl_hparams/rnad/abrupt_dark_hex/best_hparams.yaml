adam:
  b1: 0.0
  b2: 0.999
  eps: 1.0e-07
algorithm_name: rnad
batch_size: 64
c_vtrace: 1.0
clip_gradient: 20000
entropy_schedule_repeats:
- 1
entropy_schedule_size_value: 12500
eta_reward_transform: 0.2
finetune: None
learning_rate: 0.0002
nerd:
  beta: 2.0
  clip: 10000
policy_network_layers:
- 512
- 512
- 512
seed: None
state_representation: info_set
target_network_avg: 0.008
trajectory_max: 100
