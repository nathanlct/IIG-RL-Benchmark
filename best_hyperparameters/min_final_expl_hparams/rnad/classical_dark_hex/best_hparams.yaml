adam:
  b1: 0.0
  b2: 0.999
  eps: 1.0e-07
algorithm_name: rnad
batch_size: 128
c_vtrace: 0.25
clip_gradient: 2500
entropy_schedule_repeats:
- 1
entropy_schedule_size_value: 25000
eta_reward_transform: 0.025
finetune: None
learning_rate: 0.0004
nerd:
  beta: 2.0
  clip: 10000
policy_network_layers:
- 512
- 512
- 512
seed: None
state_representation: info_set
target_network_avg: 0.0005
trajectory_max: 100
